# Web Crawler CLI

A simple, lightweight command-line tool to crawl websites and collect URLs for analysis or data gathering purposes.

## ğŸš€ Features
- Crawl websites recursively
- Filter out duplicates
- Extract links from HTML pages
- Command-line arguments for customization

## ğŸ“¦ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/kelvin0916-png/1221oppt.git
   cd 1221oppt
pip install -r requirements.txt


python main.py --url https://example.com --depth 2



ğŸ™Œ Credits
Built with â¤ï¸ by kelvin0916-png

yaml
Copy
Edit

---

Do you want me to:
1. Automatically upload this to your GitHub repo?
2. Also generate a sample `requirements.txt` file?
3. Add the `LICENSE` file?

Just say the word! ğŸ˜
